{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science with Python \n",
    "## General Assembly\n",
    "## Natural Language Processing (NLP)\n",
    "\n",
    "Make sure you have installed nltk and downloaded the following copora:\n",
    "\n",
    "* punkt\n",
    "* gutenberg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Part 1\n",
    "\n",
    "###Tokenization\n",
    "\n",
    "What:  Separate text into units such as sentences or words\n",
    "\n",
    "Why:   Gives structure to previously unstructured text\n",
    "\n",
    "Notes: Relatively easy with English language text, not easy with some languages\n",
    "\n",
    "\n",
    "\"corpus\" = collection of documents\n",
    "\n",
    "\"corpora\" = plural form of corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0043f128038c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/adrian/anaconda/lib/python2.7/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error)\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;31m# function should make a new copy of self to use?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdownload_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interactive_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adrian/anaconda/lib/python2.7/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m_interactive_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mTKINTER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m                 \u001b[0mDownloaderGUI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTclError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m                 \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adrian/anaconda/lib/python2.7/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mmainloop\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1709\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m     \u001b[0;31m#/////////////////////////////////////////////////////////////////\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adrian/anaconda/lib/python2.7/lib-tk/Tkinter.pyc\u001b[0m in \u001b[0;36mmainloop\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         \u001b[0;34m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0;34m\"\"\"Quit the Tcl interpreter. All widgets will be destroyed.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import the NLTK library, and use ntlk.corpus.gutenberg.fileids() to\n",
    "# find the filenames for Jane Austen's Emma and Lewis Carrol's Alice in \n",
    "# Wonderland\n",
    "\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): textblob in /Users/adrian/anaconda/lib/python2.7/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): nltk>=3.1 in /Users/adrian/anaconda/lib/python2.7/site-packages (from textblob)\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 8.1.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'austen-emma.txt', u'austen-persuasion.txt', u'austen-sense.txt', u'bible-kjv.txt', u'blake-poems.txt', u'bryant-stories.txt', u'burgess-busterbrown.txt', u'carroll-alice.txt', u'chesterton-ball.txt', u'chesterton-brown.txt', u'chesterton-thursday.txt', u'edgeworth-parents.txt', u'melville-moby_dick.txt', u'milton-paradise.txt', u'shakespeare-caesar.txt', u'shakespeare-hamlet.txt', u'shakespeare-macbeth.txt', u'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "print nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hamlet=nltk.corpus.gutenberg.raw('shakespeare-hamlet.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-a61d47176817>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-a61d47176817>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    nltk.word_tokenize(s) for s in nltk.sent_tokenize(\"this is a sentence. this is another\");\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "nltk.word_tokenize(s) for s in nltk.sent_tokenize(\"this is a sentence. this is another\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'The'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_a_real_word(x):\n",
    "    return x not in \".,[]:;?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_hamlet = [\n",
    "    x.lower()\n",
    "        for x in nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')\n",
    "        if is_a_real_word(x)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_hamlet = []\n",
    "for x in nltk.corpus.gutenberg.words('shakespeare-hamlet.txt'):\n",
    "        if is_a_real_word(x):\n",
    "            clean_hamlet.append(x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'the',\n",
       " u'tragedie',\n",
       " u'of',\n",
       " u'hamlet',\n",
       " u'by',\n",
       " u'william',\n",
       " u'shakespeare',\n",
       " u'1599',\n",
       " u'actus',\n",
       " u'primus',\n",
       " u'scoena',\n",
       " u'prima',\n",
       " u'enter',\n",
       " u'barnardo',\n",
       " u'and',\n",
       " u'francisco',\n",
       " u'two',\n",
       " u'centinels',\n",
       " u'barnardo',\n",
       " u'who',\n",
       " u\"'\",\n",
       " u's',\n",
       " u'there',\n",
       " u'fran',\n",
       " u'nay',\n",
       " u'answer',\n",
       " u'me',\n",
       " u'stand',\n",
       " u'&',\n",
       " u'vnfold',\n",
       " u'your',\n",
       " u'selfe',\n",
       " u'bar',\n",
       " u'long',\n",
       " u'liue',\n",
       " u'the',\n",
       " u'king',\n",
       " u'fran',\n",
       " u'barnardo',\n",
       " u'bar',\n",
       " u'he',\n",
       " u'fran',\n",
       " u'you',\n",
       " u'come',\n",
       " u'most',\n",
       " u'carefully',\n",
       " u'vpon',\n",
       " u'your',\n",
       " u'houre',\n",
       " u'bar',\n",
       " u\"'\",\n",
       " u'tis',\n",
       " u'now',\n",
       " u'strook',\n",
       " u'twelue',\n",
       " u'get',\n",
       " u'thee',\n",
       " u'to',\n",
       " u'bed',\n",
       " u'francisco',\n",
       " u'fran',\n",
       " u'for',\n",
       " u'this',\n",
       " u'releefe',\n",
       " u'much',\n",
       " u'thankes',\n",
       " u\"'\",\n",
       " u'tis',\n",
       " u'bitter',\n",
       " u'cold',\n",
       " u'and',\n",
       " u'i',\n",
       " u'am',\n",
       " u'sicke',\n",
       " u'at',\n",
       " u'heart',\n",
       " u'barn',\n",
       " u'haue',\n",
       " u'you',\n",
       " u'had',\n",
       " u'quiet',\n",
       " u'guard',\n",
       " u'fran',\n",
       " u'not',\n",
       " u'a',\n",
       " u'mouse',\n",
       " u'stirring',\n",
       " u'barn',\n",
       " u'well',\n",
       " u'goodnight',\n",
       " u'if',\n",
       " u'you',\n",
       " u'do',\n",
       " u'meet',\n",
       " u'horatio',\n",
       " u'and',\n",
       " u'marcellus',\n",
       " u'the',\n",
       " u'riuals',\n",
       " u'of',\n",
       " u'my',\n",
       " u'watch',\n",
       " u'bid',\n",
       " u'them',\n",
       " u'make',\n",
       " u'hast',\n",
       " u'enter',\n",
       " u'horatio',\n",
       " u'and',\n",
       " u'marcellus',\n",
       " u'fran',\n",
       " u'i',\n",
       " u'thinke',\n",
       " u'i',\n",
       " u'heare',\n",
       " u'them',\n",
       " u'stand',\n",
       " u'who',\n",
       " u\"'\",\n",
       " u's',\n",
       " u'there',\n",
       " u'hor',\n",
       " u'friends',\n",
       " u'to',\n",
       " u'this',\n",
       " u'ground',\n",
       " u'mar',\n",
       " u'and',\n",
       " u'leige',\n",
       " u'-',\n",
       " u'men',\n",
       " u'to',\n",
       " u'the',\n",
       " u'dane',\n",
       " u'fran',\n",
       " u'giue',\n",
       " u'you',\n",
       " u'good',\n",
       " u'night',\n",
       " u'mar',\n",
       " u'o',\n",
       " u'farwel',\n",
       " u'honest',\n",
       " u'soldier',\n",
       " u'who',\n",
       " u'hath',\n",
       " u'relieu',\n",
       " u\"'\",\n",
       " u'd',\n",
       " u'you',\n",
       " u'fra',\n",
       " u'barnardo',\n",
       " u'ha',\n",
       " u\"'\",\n",
       " u's',\n",
       " u'my',\n",
       " u'place',\n",
       " u'giue',\n",
       " u'you',\n",
       " u'goodnight',\n",
       " u'exit',\n",
       " u'fran',\n",
       " u'mar',\n",
       " u'holla',\n",
       " u'barnardo',\n",
       " u'bar',\n",
       " u'say',\n",
       " u'what',\n",
       " u'is',\n",
       " u'horatio',\n",
       " u'there',\n",
       " u'hor',\n",
       " u'a',\n",
       " u'peece',\n",
       " u'of',\n",
       " u'him',\n",
       " u'bar',\n",
       " u'welcome',\n",
       " u'horatio',\n",
       " u'welcome',\n",
       " u'good',\n",
       " u'marcellus',\n",
       " u'mar',\n",
       " u'what',\n",
       " u'ha',\n",
       " u\"'\",\n",
       " u's',\n",
       " u'this',\n",
       " u'thing',\n",
       " u'appear',\n",
       " u\"'\",\n",
       " u'd',\n",
       " u'againe',\n",
       " u'to',\n",
       " u'night',\n",
       " u'bar',\n",
       " u'i',\n",
       " u'haue',\n",
       " u'seene',\n",
       " u'nothing',\n",
       " u'mar',\n",
       " u'horatio',\n",
       " u'saies',\n",
       " u\"'\",\n",
       " u'tis',\n",
       " u'but',\n",
       " u'our',\n",
       " u'fantasie',\n",
       " u'and',\n",
       " u'will',\n",
       " u'not',\n",
       " u'let',\n",
       " u'beleefe',\n",
       " u'take',\n",
       " u'hold',\n",
       " u'of',\n",
       " u'him',\n",
       " u'touching',\n",
       " u'this',\n",
       " u'dreaded',\n",
       " u'sight',\n",
       " u'twice',\n",
       " u'seene',\n",
       " u'of',\n",
       " u'vs',\n",
       " u'therefore',\n",
       " u'i',\n",
       " u'haue',\n",
       " u'intreated',\n",
       " u'him',\n",
       " u'along',\n",
       " u'with',\n",
       " u'vs',\n",
       " u'to',\n",
       " u'watch',\n",
       " u'the',\n",
       " u'minutes',\n",
       " u'of',\n",
       " u'this',\n",
       " u'night',\n",
       " u'that',\n",
       " u'if',\n",
       " u'againe',\n",
       " u'this',\n",
       " u'apparition',\n",
       " u'come',\n",
       " u'he',\n",
       " u'may',\n",
       " u'approue',\n",
       " u'our',\n",
       " u'eyes',\n",
       " u'and',\n",
       " u'speake',\n",
       " u'to',\n",
       " u'it',\n",
       " u'hor',\n",
       " u'tush',\n",
       " u'tush',\n",
       " u\"'\",\n",
       " u'twill',\n",
       " u'not',\n",
       " u'appeare',\n",
       " u'bar',\n",
       " u'sit',\n",
       " u'downe',\n",
       " u'a',\n",
       " u'-',\n",
       " u'while',\n",
       " u'and',\n",
       " u'let',\n",
       " u'vs',\n",
       " u'once',\n",
       " u'againe',\n",
       " u'assaile',\n",
       " u'your',\n",
       " u'eares',\n",
       " u'that',\n",
       " u'are',\n",
       " u'so',\n",
       " u'fortified',\n",
       " u'against',\n",
       " u'our',\n",
       " u'story',\n",
       " u'what',\n",
       " u'we',\n",
       " u'two',\n",
       " u'nights',\n",
       " u'haue',\n",
       " u'seene',\n",
       " u'hor',\n",
       " u'well',\n",
       " u'sit',\n",
       " u'we',\n",
       " u'downe',\n",
       " u'and',\n",
       " u'let',\n",
       " u'vs',\n",
       " u'heare',\n",
       " u'barnardo',\n",
       " u'speake',\n",
       " u'of',\n",
       " u'this',\n",
       " u'barn',\n",
       " u'last',\n",
       " u'night',\n",
       " u'of',\n",
       " u'all',\n",
       " u'when',\n",
       " u'yond',\n",
       " u'same',\n",
       " u'starre',\n",
       " u'that',\n",
       " u\"'\",\n",
       " u's',\n",
       " u'westward',\n",
       " u'from',\n",
       " u'the',\n",
       " u'pole',\n",
       " u'had',\n",
       " u'made',\n",
       " u'his',\n",
       " u'course',\n",
       " u't',\n",
       " u\"'\",\n",
       " u'illume',\n",
       " u'that',\n",
       " u'part',\n",
       " u'of',\n",
       " u'heauen',\n",
       " u'where',\n",
       " u'now',\n",
       " u'it',\n",
       " u'burnes',\n",
       " u'marcellus',\n",
       " u'and',\n",
       " u'my',\n",
       " u'selfe',\n",
       " u'the',\n",
       " u'bell',\n",
       " u'then',\n",
       " u'beating',\n",
       " u'one',\n",
       " u'mar',\n",
       " u'peace',\n",
       " u'breake',\n",
       " u'thee',\n",
       " u'of',\n",
       " u'enter',\n",
       " u'the',\n",
       " u'ghost',\n",
       " u'looke',\n",
       " u'where',\n",
       " u'it',\n",
       " u'comes',\n",
       " u'againe',\n",
       " u'barn',\n",
       " u'in',\n",
       " u'the',\n",
       " u'same',\n",
       " u'figure',\n",
       " u'like',\n",
       " u'the',\n",
       " u'king',\n",
       " u'that',\n",
       " u\"'\",\n",
       " u's',\n",
       " u'dead',\n",
       " u'mar',\n",
       " u'thou',\n",
       " u'art',\n",
       " u'a',\n",
       " u'scholler',\n",
       " u'speake',\n",
       " u'to',\n",
       " u'it',\n",
       " u'horatio',\n",
       " u'barn',\n",
       " u'lookes',\n",
       " u'it',\n",
       " u'not',\n",
       " u'like',\n",
       " u'the',\n",
       " u'king',\n",
       " u'marke',\n",
       " u'it',\n",
       " u'horatio',\n",
       " u'hora',\n",
       " u'most',\n",
       " u'like',\n",
       " u'it',\n",
       " u'harrowes',\n",
       " u'me',\n",
       " u'with',\n",
       " u'fear',\n",
       " u'&',\n",
       " u'wonder',\n",
       " u'barn',\n",
       " u'it',\n",
       " u'would',\n",
       " u'be',\n",
       " u'spoke',\n",
       " u'too',\n",
       " u'mar',\n",
       " u'question',\n",
       " u'it',\n",
       " u'horatio',\n",
       " u'hor',\n",
       " u'what',\n",
       " u'art',\n",
       " u'thou',\n",
       " u'that',\n",
       " u'vsurp',\n",
       " u\"'\",\n",
       " u'st',\n",
       " u'this',\n",
       " u'time',\n",
       " u'of',\n",
       " u'night',\n",
       " u'together',\n",
       " u'with',\n",
       " u'that',\n",
       " u'faire',\n",
       " u'and',\n",
       " u'warlike',\n",
       " u'forme',\n",
       " u'in',\n",
       " u'which',\n",
       " u'the',\n",
       " u'maiesty',\n",
       " u'of',\n",
       " u'buried',\n",
       " u'denmarke',\n",
       " u'did',\n",
       " u'sometimes',\n",
       " u'march',\n",
       " u'by',\n",
       " u'heauen',\n",
       " u'i',\n",
       " u'charge',\n",
       " u'thee',\n",
       " u'speake',\n",
       " u'mar',\n",
       " u'it',\n",
       " u'is',\n",
       " u'offended',\n",
       " u'barn',\n",
       " u'see',\n",
       " u'it',\n",
       " u'stalkes',\n",
       " u'away',\n",
       " u'hor',\n",
       " u'stay',\n",
       " u'speake',\n",
       " u'speake',\n",
       " u'i',\n",
       " u'charge',\n",
       " u'thee',\n",
       " u'speake',\n",
       " u'exit',\n",
       " u'the',\n",
       " u'ghost',\n",
       " u'mar',\n",
       " u\"'\",\n",
       " u'tis',\n",
       " u'gone',\n",
       " u'and',\n",
       " u'will',\n",
       " u'not',\n",
       " u'answer',\n",
       " u'barn',\n",
       " u'how',\n",
       " u'now',\n",
       " u'horatio',\n",
       " u'you',\n",
       " u'tremble',\n",
       " u'&',\n",
       " u'look',\n",
       " u'pale',\n",
       " u'is',\n",
       " u'not',\n",
       " u'this',\n",
       " u'something',\n",
       " u'more',\n",
       " u'then',\n",
       " u'fantasie',\n",
       " u'what',\n",
       " u'thinke',\n",
       " u'you',\n",
       " u'on',\n",
       " u\"'\",\n",
       " u't',\n",
       " u'hor',\n",
       " u'before',\n",
       " u'my',\n",
       " u'god',\n",
       " u'i',\n",
       " u'might',\n",
       " u'not',\n",
       " u'this',\n",
       " u'beleeue',\n",
       " u'without',\n",
       " u'the',\n",
       " u'sensible',\n",
       " u'and',\n",
       " u'true',\n",
       " u'auouch',\n",
       " u'of',\n",
       " u'mine',\n",
       " u'owne',\n",
       " u'eyes',\n",
       " u'mar',\n",
       " u'is',\n",
       " u'it',\n",
       " u'not',\n",
       " u'like',\n",
       " u'the',\n",
       " u'king',\n",
       " u'hor',\n",
       " u'as',\n",
       " u'thou',\n",
       " u'art',\n",
       " u'to',\n",
       " u'thy',\n",
       " u'selfe',\n",
       " u'such',\n",
       " u'was',\n",
       " u'the',\n",
       " u'very',\n",
       " u'armour',\n",
       " u'he',\n",
       " u'had',\n",
       " u'on',\n",
       " u'when',\n",
       " u'th',\n",
       " u\"'\",\n",
       " u'ambitious',\n",
       " u'norwey',\n",
       " u'combatted',\n",
       " u'so',\n",
       " u'frown',\n",
       " u\"'\",\n",
       " u'd',\n",
       " u'he',\n",
       " u'once',\n",
       " u'when',\n",
       " u'in',\n",
       " u'an',\n",
       " u'angry',\n",
       " u'parle',\n",
       " u'he',\n",
       " u'smot',\n",
       " u'the',\n",
       " u'sledded',\n",
       " u'pollax',\n",
       " u'on',\n",
       " u'the',\n",
       " u'ice',\n",
       " u\"'\",\n",
       " u'tis',\n",
       " u'strange',\n",
       " u'mar',\n",
       " u'thus',\n",
       " u'twice',\n",
       " u'before',\n",
       " u'and',\n",
       " u'iust',\n",
       " u'at',\n",
       " u'this',\n",
       " u'dead',\n",
       " u'houre',\n",
       " u'with',\n",
       " u'martiall',\n",
       " u'stalke',\n",
       " u'hath',\n",
       " u'he',\n",
       " u'gone',\n",
       " u'by',\n",
       " u'our',\n",
       " u'watch',\n",
       " u'hor',\n",
       " u'in',\n",
       " u'what',\n",
       " u'particular',\n",
       " u'thought',\n",
       " u'to',\n",
       " u'work',\n",
       " u'i',\n",
       " u'know',\n",
       " u'not',\n",
       " u'but',\n",
       " u'in',\n",
       " u'the',\n",
       " u'grosse',\n",
       " u'and',\n",
       " u'scope',\n",
       " u'of',\n",
       " u'my',\n",
       " u'opinion',\n",
       " u'this',\n",
       " u'boades',\n",
       " u'some',\n",
       " u'strange',\n",
       " u'erruption',\n",
       " u'to',\n",
       " u'our',\n",
       " u'state',\n",
       " u'mar',\n",
       " u'good',\n",
       " u'now',\n",
       " u'sit',\n",
       " u'downe',\n",
       " u'&',\n",
       " u'tell',\n",
       " u'me',\n",
       " u'he',\n",
       " u'that',\n",
       " u'knowes',\n",
       " u'why',\n",
       " u'this',\n",
       " u'same',\n",
       " u'strict',\n",
       " u'and',\n",
       " u'most',\n",
       " u'obseruant',\n",
       " u'watch',\n",
       " u'so',\n",
       " u'nightly',\n",
       " u'toyles',\n",
       " u'the',\n",
       " u'subiect',\n",
       " u'of',\n",
       " u'the',\n",
       " u'land',\n",
       " u'and',\n",
       " u'why',\n",
       " u'such',\n",
       " u'dayly',\n",
       " u'cast',\n",
       " u'of',\n",
       " u'brazon',\n",
       " u'cannon',\n",
       " u'and',\n",
       " u'forraigne',\n",
       " u'mart',\n",
       " u'for',\n",
       " u'implements',\n",
       " u'of',\n",
       " u'warre',\n",
       " u'why',\n",
       " u'such',\n",
       " u'impresse',\n",
       " u'of',\n",
       " u'ship',\n",
       " u'-',\n",
       " u'wrights',\n",
       " u'whose',\n",
       " u'sore',\n",
       " u'taske',\n",
       " u'do',\n",
       " u\"'\",\n",
       " u's',\n",
       " u'not',\n",
       " u'diuide',\n",
       " u'the',\n",
       " u'sunday',\n",
       " u'from',\n",
       " u'the',\n",
       " u'weeke',\n",
       " u'what',\n",
       " u'might',\n",
       " u'be',\n",
       " u'toward',\n",
       " u'that',\n",
       " u'this',\n",
       " u'sweaty',\n",
       " u'hast',\n",
       " u'doth',\n",
       " u'make',\n",
       " u'the',\n",
       " u'night',\n",
       " u'ioynt',\n",
       " u'-',\n",
       " u'labourer',\n",
       " u'with',\n",
       " u'the',\n",
       " u'day',\n",
       " u'who',\n",
       " u'is',\n",
       " u\"'\",\n",
       " u't',\n",
       " u'that',\n",
       " u'can',\n",
       " u'informe',\n",
       " u'me',\n",
       " u'hor',\n",
       " u'that',\n",
       " u'can',\n",
       " u'i',\n",
       " u'at',\n",
       " u'least',\n",
       " u'the',\n",
       " u'whisper',\n",
       " u'goes',\n",
       " u'so',\n",
       " u'our',\n",
       " u'last',\n",
       " u'king',\n",
       " u'whose',\n",
       " u'image',\n",
       " u'euen',\n",
       " u'but',\n",
       " u'now',\n",
       " u'appear',\n",
       " u\"'\",\n",
       " u'd',\n",
       " u'to',\n",
       " u'vs',\n",
       " u'was',\n",
       " u'(',\n",
       " u'as',\n",
       " u'you',\n",
       " u'know',\n",
       " u')',\n",
       " u'by',\n",
       " u'fortinbras',\n",
       " u'of',\n",
       " u'norway',\n",
       " u'(',\n",
       " u'thereto',\n",
       " u'prick',\n",
       " u\"'\",\n",
       " u'd',\n",
       " u'on',\n",
       " u'by',\n",
       " u'a',\n",
       " u'most',\n",
       " u'emulate',\n",
       " u'pride',\n",
       " u')',\n",
       " u'dar',\n",
       " u\"'\",\n",
       " u'd',\n",
       " u'to',\n",
       " u'the',\n",
       " u'combate',\n",
       " u'in',\n",
       " u'which',\n",
       " u'our',\n",
       " u'valiant',\n",
       " u'hamlet',\n",
       " u'(',\n",
       " u'for',\n",
       " u'so',\n",
       " u'this',\n",
       " u'side',\n",
       " u'of',\n",
       " u'our',\n",
       " u'knowne',\n",
       " u'world',\n",
       " u'esteem',\n",
       " u\"'\",\n",
       " u'd',\n",
       " u'him',\n",
       " u')',\n",
       " u'did',\n",
       " u'slay',\n",
       " u'this',\n",
       " u'fortinbras',\n",
       " u'who',\n",
       " u'by',\n",
       " u'a',\n",
       " u'seal',\n",
       " u\"'\",\n",
       " u'd',\n",
       " u'compact',\n",
       " u'well',\n",
       " u'ratified',\n",
       " u'by',\n",
       " u'law',\n",
       " u'and',\n",
       " u'heraldrie',\n",
       " u'did',\n",
       " u'forfeite',\n",
       " u'(',\n",
       " u'with',\n",
       " u'his',\n",
       " u'life',\n",
       " u')',\n",
       " u'all',\n",
       " u'those',\n",
       " u'his',\n",
       " u'lands',\n",
       " u'which',\n",
       " u'he',\n",
       " u'stood',\n",
       " u'seiz',\n",
       " u\"'\",\n",
       " u'd',\n",
       " u'on',\n",
       " u'to',\n",
       " u'the',\n",
       " u'conqueror',\n",
       " u'against',\n",
       " u'the',\n",
       " u'which',\n",
       " u'a',\n",
       " u'moity',\n",
       " u'competent',\n",
       " u'was',\n",
       " u'gaged',\n",
       " u'by',\n",
       " u'our',\n",
       " u'king',\n",
       " u'which',\n",
       " u'had',\n",
       " u'return',\n",
       " u\"'\",\n",
       " u'd',\n",
       " u'to',\n",
       " u'the',\n",
       " u'inheritance',\n",
       " u'of',\n",
       " u'fortinbras',\n",
       " u'had',\n",
       " u'he',\n",
       " u'bin',\n",
       " u'vanquisher',\n",
       " u'as',\n",
       " u'by',\n",
       " u'the',\n",
       " u'same',\n",
       " u'cou',\n",
       " u\"'\",\n",
       " u'nant',\n",
       " u'and',\n",
       " u'carriage',\n",
       " u'of',\n",
       " u'the',\n",
       " u'article',\n",
       " u'designe',\n",
       " u'his',\n",
       " u'fell',\n",
       " u'to',\n",
       " u'hamlet',\n",
       " u'now',\n",
       " u'sir',\n",
       " u'young',\n",
       " u'fortinbras',\n",
       " u'of',\n",
       " u'vnimproued',\n",
       " u'mettle',\n",
       " u'hot',\n",
       " u'and',\n",
       " u'full',\n",
       " u'hath',\n",
       " u'in',\n",
       " u'the',\n",
       " u'skirts',\n",
       " u'of',\n",
       " u'norway',\n",
       " u'heere',\n",
       " u'and',\n",
       " u'there',\n",
       " u'shark',\n",
       " u\"'\",\n",
       " u'd',\n",
       " u'vp',\n",
       " u'a',\n",
       " u'list',\n",
       " u'of',\n",
       " u'landlesse',\n",
       " u'resolutes',\n",
       " u'for',\n",
       " u'foode',\n",
       " u'and',\n",
       " u'diet',\n",
       " u'to',\n",
       " u'some',\n",
       " u'enterprize',\n",
       " u'that',\n",
       " u'hath',\n",
       " u'a',\n",
       " u'stomacke',\n",
       " u'in',\n",
       " u\"'\",\n",
       " u't',\n",
       " u'which',\n",
       " u'is',\n",
       " u'no',\n",
       " u'other',\n",
       " u'(',\n",
       " u'and',\n",
       " u'it',\n",
       " u'doth',\n",
       " u'well',\n",
       " u'appeare',\n",
       " u'vnto',\n",
       " u'our',\n",
       " u'state',\n",
       " u')',\n",
       " u'but',\n",
       " u'to',\n",
       " u'recouer',\n",
       " u'of',\n",
       " u'vs',\n",
       " u'by',\n",
       " u'strong',\n",
       " u'hand',\n",
       " u'and',\n",
       " u'termes',\n",
       " u'compulsatiue',\n",
       " u'those',\n",
       " u'foresaid',\n",
       " u'lands',\n",
       " u'so',\n",
       " u'by',\n",
       " u'his',\n",
       " u'father',\n",
       " u'lost',\n",
       " u'and',\n",
       " u'this',\n",
       " u'(',\n",
       " u'i',\n",
       " u'take',\n",
       " u'it',\n",
       " u')',\n",
       " u'is',\n",
       " u'the',\n",
       " u'maine',\n",
       " u'motiue',\n",
       " u'of',\n",
       " u'our',\n",
       " u'preparations',\n",
       " u'the',\n",
       " u'sourse',\n",
       " u'of',\n",
       " u'this',\n",
       " u'our',\n",
       " u'watch',\n",
       " u'and',\n",
       " u'the',\n",
       " u'cheefe',\n",
       " u'head',\n",
       " u'of',\n",
       " u'this',\n",
       " u'post',\n",
       " u'-',\n",
       " u'hast',\n",
       " u'and',\n",
       " u'romage',\n",
       " u'in',\n",
       " u'the',\n",
       " u'land',\n",
       " u'enter',\n",
       " u'ghost',\n",
       " u'againe',\n",
       " u'but',\n",
       " u'soft',\n",
       " u'behold',\n",
       " u'loe',\n",
       " u'where',\n",
       " u'it',\n",
       " u'comes',\n",
       " u'againe',\n",
       " u'ile',\n",
       " u'crosse',\n",
       " u'it',\n",
       " u'though',\n",
       " u'it',\n",
       " u'blast',\n",
       " u'me',\n",
       " u'stay',\n",
       " u'illusion',\n",
       " u'if',\n",
       " u'thou',\n",
       " u'hast',\n",
       " u'any',\n",
       " u'sound',\n",
       " u'or',\n",
       " u'vse',\n",
       " u'of',\n",
       " u'voyce',\n",
       " u'speake',\n",
       " u'to',\n",
       " u'me',\n",
       " u'if',\n",
       " u'there',\n",
       " u'be',\n",
       " u'any',\n",
       " u'good',\n",
       " u'thing',\n",
       " u'to',\n",
       " u'be',\n",
       " u'done',\n",
       " u'that',\n",
       " u'may',\n",
       " u'to',\n",
       " u'thee',\n",
       " u'do',\n",
       " u'ease',\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_hamlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31251"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_words = set(clean_hamlet)\n",
    "len(distinct_words)\n",
    "len(clean_hamlet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15068317813829957"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diversity = len(distinct_words)*1.0/len(clean_hamlet)\n",
    "diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hamlet_object = nltk.Text(nltk.corpus.gutenberg.words('shakespeare-hamlet.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 40 matches:\n",
      ". Well , goodnight . If you do meet Horatio and Marcellus , the Riuals of my Wa\n",
      " Watch , bid them make hast . Enter Horatio and Marcellus . Fran . I thinke I h\n",
      " Holla Barnardo Bar . Say , what is Horatio there ? Hor . A peece of him Bar . \n",
      " Hor . A peece of him Bar . Welcome Horatio , welcome good Marcellus Mar . What\n",
      "ht Bar . I haue seene nothing Mar . Horatio saies , ' tis but our Fantasie , An\n",
      " Thou art a Scholler ; speake to it Horatio Barn . Lookes it not like the King \n",
      "kes it not like the King ? Marke it Horatio Hora . Most like : It harrowes me w\n",
      "ould be spoke too Mar . Question it Horatio Hor . What art thou that vsurp ' st\n",
      " and will not answer Barn . How now Horatio ? You tremble & look pale : Is not \n",
      ", for I must hold my tongue . Enter Horatio , Barnardo , and Marcellus . Hor . \n",
      "p Ham . I am glad to see you well : Horatio , or I do forget my selfe Hor . The\n",
      ": And what make you from Wittenberg Horatio ? Marcellus Mar . My good Lord Ham \n",
      "lowed hard vpon Ham . Thrift thrift Horatio : the Funerall Bakt - meats Did col\n",
      "uen , Ere I had euer seene that day Horatio . My father , me thinkes I see my f\n",
      "e my Lord ? Ham . In my minds eye ( Horatio ) Hor . I saw him once ; he was a g\n",
      "y my Lord . Exeunt . Enter Hamlet , Horatio , Marcellus . Ham . The Ayre bites \n",
      " within . My Lord , my Lord . Enter Horatio and Marcellus . Mar . Lord Hamlet H\n",
      "e more things in Heauen and Earth , Horatio , Then are dream ' t of in our Phil\n",
      " . We will my Lord . Exeunt . Enter Horatio . Ham . What hoa , Horatio ? Hora .\n",
      " . Enter Horatio . Ham . What hoa , Horatio ? Hora . Heere sweet Lord , at your\n",
      " sweet Lord , at your Seruice Ham . Horatio , thou art eene as iust a man As er\n",
      " , Lights . Exeunt . Manet Hamlet & Horatio . Ham . Why let the strucken Deere \n",
      "ou might haue Rim ' d Ham . Oh good Horatio , Ile take the Ghosts word for a th\n",
      "afely on . Enter . Enter Queene and Horatio . Qu . I will not speake with her H\n",
      "ray you go with me . Exeunt . Enter Horatio , with an Attendant . Hora . What a\n"
     ]
    }
   ],
   "source": [
    "hamlet_object.concordance('Horatio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",_, and_. (_) :_, thrift_: meet_and now_? ,_? day_. wittenberg_?\n",
      "welcome_, is_there lord_, returne_. good_wait dye_: and_ham him_,\n",
      "enter_, ._,\n"
     ]
    }
   ],
   "source": [
    "hamlet_object.common_contexts(['Horatio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamlet laertes king ophelia polonius well come go guildensterne now\n",
      "out lord oh sir no queene mother adue ha gentlemen\n"
     ]
    }
   ],
   "source": [
    "hamlet_object.similar('Horatio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hamlet_object.dispersion_plot(['Horatio', 'Opelia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Break these novels up into sentences. Put these sentence lists into\n",
    "# a list so that you can use it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count the number of sentences in each novel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Break each sentence up into words. You will end up with a \n",
    "# list of lists of words for Emma and another one for Alice in\n",
    "# Wonderland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count the number of words in each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Which novel has more average words per sentence?\n",
    "# Given their target audience, is this what you would expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a flat list (i.e. not a list of lists) of words in\n",
    "# the two novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For each novel, construct a set of all the distinct words used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the lexical diversity of each novel (distinct words / word count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (Optional, only for the very keen)\n",
    "# Repeat the above analysis for all the Gutenberg samples\n",
    "# Create a dataframe with the names of the novels, when they were written,\n",
    "# whether they were for children, the lexical diversity and the average sentence length.\n",
    "# Can you use logistic regression to predict the audience, based on the content?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Part 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make nltk.Text objects from the two novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Does Jane Austen ever mention the word 'young' in Emma? What about Lewis Carroll?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What are the common contexts for these words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Where does the word 'cat' appear in Alice and Wonderland?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Part 3\n",
    "\n",
    "###Stemming\n",
    "What:  Reduce a word to its base/stem form\n",
    "\n",
    "Why:   Often makes sense to treat multiple word forms the same way\n",
    "\n",
    "Notes: Uses a \"simple\" and fast rule-based approach\n",
    "       Output can be undesirable for irregular words\n",
    "       Stemmed words are usually not shown to users (used for analysis/indexing)\n",
    "       Some search engines treat words with the same stem as synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an English stemmer that uses the Snowball technique\n",
    "# nltk.stem.snowball.SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stem the following words: charge, charging, charged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Can you stem \"words\" with punctuation in them? Or which have no letters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new list of words from the novels by dropping out spurious non-words.\n",
    "# You might find word_is_just_letters() helpful\n",
    "def word_is_just_letters(word):\n",
    "    import re\n",
    "    return re.search('^[a-zA-Z]+', word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stem all those words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create two collections.Counter objects (one for each novel)\n",
    "# so that you can easily count word stems. If you give\n",
    "# the stemmed lists as an argument to constructor, \n",
    "# you can use .most_common(25) to get the top 25 tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Lemmatization / synset\n",
    "What:  Derive the canonical form ('lemma') of a word\n",
    "    \n",
    "Why:   Can be better than stemming, reduces words to a 'normal' form.\n",
    "    \n",
    "Notes: Uses a dictionary-based approach (slower than stemming)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What synsets does 'dog' belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Which synset is the one you were thinking of?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What is its hypernym?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What about wolves? What synsets does it belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How closely related are those concepts (dogs and wolves)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How closely related are the concepts 'dog' and 'novel'?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Part 3 Part of speech tagging\n",
    "\n",
    "Other:\n",
    "- Analysing data with the Alchemy API\n",
    "- Further Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part of Speech Tagging\n",
    "\n",
    "What:  Determine the part of speech of a word\n",
    "    \n",
    "Why:   This can inform other methods and models such as Named Entity Recognition\n",
    "    \n",
    "Notes: http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use nltk.pos_tag to parse a sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (Optional for the enthusiastic)\n",
    "# What verbs did Jane Austen use a lot of?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Part 4\n",
    "###Stopword Removal\n",
    "\n",
    "What:  Remove common words that will likely appear in any text\n",
    "    \n",
    "Why:   They don't tell you much about your text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# most of top 25 stemmed tokens are \"worthless\"\n",
    "c.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# view the list of stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "sorted(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################\n",
    "### Exercise  ####\n",
    "##################\n",
    "\n",
    "\n",
    "# Create a variable called stemmed_stops which is the \n",
    "# stemmed version of each stopword in stopwords\n",
    "# Use the stemmer we used up above!\n",
    "\n",
    "# Then create a list called stemmed_tokens_no_stop that \n",
    "# contains only the tokens in stemmed_tokens that aren't in \n",
    "# stemmed_stops\n",
    "\n",
    "# Show the 25 most common stemmed non stop word tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Part 5\n",
    "###Named Entity Recognition\n",
    "\n",
    "What:  Automatically extract the names of people, places, organizations, etc.\n",
    "\n",
    "Why:   Can help you to identify \"important\" words\n",
    "\n",
    "Notes: Training NER classifier requires a lot of annotated training data\n",
    "       Should be trained on data relevant to your task\n",
    "       Stanford NER classifier is the \"gold standard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = 'Ian is an instructor for General Assembly'\n",
    "\n",
    "tokenized = nltk.word_tokenize(sentence)\n",
    "\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged = nltk.pos_tag(tokenized)\n",
    "\n",
    "tagged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chunks = nltk.ne_chunk(tagged)\n",
    "\n",
    "chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    entities = []\n",
    "    # tokenize into sentences\n",
    "    for sentence in nltk.sent_tokenize(text):\n",
    "        # tokenize sentences into words\n",
    "        # add part-of-speech tags\n",
    "        # use NLTK's NER classifier\n",
    "        chunks = nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sentence)))\n",
    "        # parse the results\n",
    "        entities.extend([chunk for chunk in chunks if hasattr(chunk, 'label')])\n",
    "    return entities\n",
    "\n",
    "for entity in extract_entities('Ian is an instructor for General Assembly'):\n",
    "    print '[' + entity.label() + '] ' + ' '.join(c[0] for c in entity.leaves())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Part 6\n",
    "###Term Frequency - Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "What:  Computes \"relative frequency\" that a word appears in a document\n",
    "           compared to its frequency across all documents\n",
    "\n",
    "Why:   More useful than \"term frequency\" for identifying \"important\" words in\n",
    "           each document (high frequency in that document, low frequency in\n",
    "           other documents)\n",
    "\n",
    "Notes: Used for search engine scoring, text summarization, document clustering\n",
    "\n",
    "How: \n",
    "    TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "    IDF(t) = log_e(Total number of documents / Number of documents with term t in it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = ['Bob likes sports', 'Bob hates sports', 'Bob likes likes trees']\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Each row represents a sentence\n",
    "# Each column represents a word\n",
    "vect.fit_transform(sample).toarray()\n",
    "vect.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit_transform(sample).toarray()\n",
    "tfidf.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the IDF of each word\n",
    "idf = tfidf.idf_\n",
    "print dict(zip(tfidf.get_feature_names(), idf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############\n",
    "## Exercise ###\n",
    "###############\n",
    "\n",
    "\n",
    "# for each sentence in sample, find the most \"interesting \n",
    "#words\" by ordering their tfidf in ascending order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Part 7\n",
    "\n",
    "###LDA - Latent Dirichlet Allocation\n",
    "\n",
    "What:  Way of automatically discovering topics from sentences\n",
    "\n",
    "Why:   Much quicker than manually creating and identifying topic clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lda\n",
    "\n",
    "# Instantiate a count vectorizer with two additional parameters\n",
    "vect = CountVectorizer(stop_words='english', ngram_range=[1,3]) \n",
    "sentences_train = vect.fit_transform(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate an LDA model\n",
    "model = lda.LDA(n_topics=10, n_iter=500)\n",
    "model.fit(sentences_train) # Fit the model \n",
    "n_top_words = 10\n",
    "topic_word = model.topic_word_\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vect.get_feature_names())[np.argsort(topic_dist)][:-n_top_words:-1]\n",
    "    print('Topic {}: {}'.format(i, ', '.join(topic_words)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EXAMPLE: Automatically summarize a document\n",
    "\n",
    "\n",
    "# corpus of 2000 movie reviews\n",
    "from nltk.corpus import movie_reviews\n",
    "reviews = [movie_reviews.raw(filename) for filename in movie_reviews.fileids()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create document-term matrix\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "dtm = tfidf.fit_transform(reviews)\n",
    "features = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the most and least \"interesting\" sentences in a randomly selected review\n",
    "def summarize():\n",
    "    \n",
    "    # choose a random movie review    \n",
    "    review_id = np.random.randint(0, len(reviews))\n",
    "    review_text = reviews[review_id]\n",
    "\n",
    "    # we are going to score each sentence in the review for \"interesting-ness\"\n",
    "    sent_scores = []\n",
    "    # tokenize document into sentences\n",
    "    for sentence in nltk.sent_tokenize(review_text):\n",
    "        # exclude short sentences\n",
    "        if len(sentence) > 6:\n",
    "            score = 0\n",
    "            token_count = 0\n",
    "            # tokenize sentence into words\n",
    "            tokens = nltk.word_tokenize(sentence)\n",
    "            # compute sentence \"score\" by summing TFIDF for each word\n",
    "            for token in tokens:\n",
    "                if token in features:\n",
    "                    score += dtm[review_id, features.index(token)]\n",
    "                    token_count += 1\n",
    "            # divide score by number of tokens\n",
    "            sent_scores.append((score / float(token_count + 1), sentence))\n",
    "\n",
    "    # lowest scoring sentences\n",
    "    print '\\nLOWEST:\\n'\n",
    "    for sent_score in sorted(sent_scores)[:3]:\n",
    "        print sent_score[1]\n",
    "\n",
    "    # highest scoring sentences\n",
    "    print '\\nHIGHEST:\\n'\n",
    "    for sent_score in sorted(sent_scores, reverse=True)[:3]:\n",
    "        print sent_score[1]\n",
    "\n",
    "# try it out!\n",
    "summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Part 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TextBlob Demo: \"Simplified Text Processing\"\n",
    "# Installation: pip install textblob\n",
    "! pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# identify words and noun phrases\n",
    "blob = TextBlob('Greg and Adrian are instructors for General Assembly')\n",
    "blob.words\n",
    "blob.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sentiment analysis\n",
    "blob = TextBlob('I hate this horrible movie. This movie is not very good.')\n",
    "blob.sentences\n",
    "blob.sentiment.polarity\n",
    "[sent.sentiment.polarity for sent in blob.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sentiment subjectivity\n",
    "TextBlob(\"I am a cool person\").sentiment.subjectivity # Pretty subjective\n",
    "TextBlob(\"I am a person\").sentiment.subjectivity # Pretty objective\n",
    "# different scores for essentially the same sentence\n",
    "print TextBlob('Greg and Adrian are instructors for General Assembly in Sydney').sentiment.subjectivity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# singularize and pluralize\n",
    "blob = TextBlob('Put away the dishes.')\n",
    "[word.singularize() for word in blob.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[word.pluralize() for word in blob.words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spelling correction\n",
    "blob = TextBlob('15 minuets late')\n",
    "blob.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spellcheck\n",
    "Word('parot').spellcheck()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# definitions\n",
    "Word('bank').define()\n",
    "Word('bank').define('v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# translation and language identification\n",
    "blob = TextBlob('Welcome to the classroom.')\n",
    "blob.translate(to='es')\n",
    "blob = TextBlob('Hola amigos')\n",
    "blob.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
